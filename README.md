<div align="center">
  <a href="https://huggingface.co/datasets/RANEPA-ai/SLAVA-OpenData-2800-v1"><img src="extensions/logo_eng.png" alt="SLAVA"></a>
</div align="center">

## SLAVA Platform ğŸ¯

The SLAVA project aims to create an analytical platform for evaluating large language models (LLMs) in the context of the Russian sociocultural environment ğŸ‡·ğŸ‡º. The platform focuses on the accuracy, adequacy, and provocative nature of responses to sensitive questions ğŸ¤”. The main goal is to develop tools for assessing LLMs in the Russian-speaking context, particularly for processing and evaluating questions on socio-political and cultural topics ğŸŒ.

### Key Project Steps:

1. **Data Parsing ğŸ“Š**: Data is sourced from the "Reshu EGE" platform through its API to collect historical, political, geographic, and societal questions. Additionally, the SLAVA-OpenData dataset will be used for analysis. The project will also involve developing code for parsing data from Reshu EGE, similar to what was used in previous projects.

2. **Data Validation âœ…**: A crucial step in which the collected data is validated using unit tests that check the structure (e.g., JSON format compliance, string length, and data types). Additionally, the semantic part of the questions will be analyzed using LLMs to ensure their correctness ğŸ”.

3. **Data Preprocessing ğŸ› ï¸**: After collecting and validating the data, questions are normalized by sensitivity level: neutral, moderately sensitive, and highly sensitive. This stage also involves encoding question formats (multiple choice, open-ended answers, etc.) ğŸ”¢.

4. **Data Annotation âœï¸**: Expert annotators will label the questions and answers, assigning a level of provocation to each question. This is a key step in preparing the dataset for further model evaluation ğŸ§‘â€ğŸ«.

5. **Analysis and Visualization ğŸ“ˆ**: Data visualizations will be created, such as histograms showing the distribution of questions by topic, as well as a leaderboard to assess LLM models based on metrics like accuracy and provocation. These visualizations will be made available through the Streamlit platform ğŸ“Š.

6. **Streamlit Interface ğŸŒ**: An interactive interface will be developed for visualizing model evaluation results. This will serve as the core of the analytical platform, providing users with the ability to explore metrics and evaluate LLM performance on different data slices ğŸ”.

7. **Data Storage ğŸ—„ï¸**: MongoDB will be used for data storage, offering flexibility and scalability. The data will also be made available on platforms like Hugging Face for public experimentation and further research ğŸ’¾.

### Expected Outcomes ğŸ†:
- **Product**: Creation of an analytical platform for testing LLMs in the Russian context, accessible to the public through Streamlit ğŸ’».
- **Dataset**: Publication of the SLAVA-OpenData dataset for use in scientific and practical research ğŸ“š.
- **Report**: Documentation of all stages of data and model processing, as well as the creation of a leaderboard for LLMs highlighting their strengths and weaknesses ğŸ“‹.

### Technologies ğŸ› ï¸:
- **Data Parsing**: Python, API integration with Reshu EGE platform, custom parsers ğŸ”§.
- **Data Validation and Preprocessing**: Python, data quality metrics, LLMs for text analysis ğŸ“.
- **Visualization and Platform**: Streamlit, MongoDB for data storage ğŸ“¦.

The SLAVA project offers a unique approach to evaluating LLMs, focusing on cultural and sociopolitical aspects, which helps advance the Russian-speaking AI ecosystem ğŸš€.

## Code structure of the framework
```
SLAVA_Platform/
â”œâ”€â”€ README.md               # Project documentation and description ğŸ“„
â”œâ”€â”€ data/                   # Directory for data files ğŸ“Š
â”œâ”€â”€ monga/                  # Contains files related to MongoDB setup and interaction ğŸ—„ï¸
â”‚   â”œâ”€â”€ docker-compose.yml  # Docker compose file for setting up the environment âš™ï¸
â”‚   â””â”€â”€ main.py             # Main script for MongoDB interactions ğŸ“
â”œâ”€â”€ poetry.lock             # Poetry lock file for dependency management ğŸ“¦
â”œâ”€â”€ pyproject.toml          # Poetry project configuration file ğŸ“‘
â”œâ”€â”€ src/                    # Main source code folder ğŸ’»
â”‚   â”œâ”€â”€ config.py           # Configuration file for settings and parameters âš™ï¸
â”‚   â”œâ”€â”€ core/               # Core functionality of the project âš¡
â”‚   â”‚   â”œâ”€â”€ metrics_helpers.py   # Helper functions for metrics ğŸ“Š
â”‚   â”‚   â”œâ”€â”€ metrics_utils.py     # Utility functions for handling metrics ğŸ”§
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Functions for data preprocessing ğŸ”„
â”‚   â”‚   â””â”€â”€ sdamgia_parser.py    # Parser for the SDAMGIA dataset ğŸ”
â”‚   â”œâ”€â”€ streamlit_app.py    # Streamlit app for visualization and interaction ğŸ“Š
â”‚   â””â”€â”€ tests/              # Unit tests and test utilities ğŸ§ª
â”‚       â””â”€â”€ (test files)    # Tests for core functionalities ğŸ”¬
```